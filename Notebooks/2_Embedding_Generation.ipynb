{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Sentence Embedding Generation\n",
    "\n",
    "In this notebook, we generate vector representations (embeddings) for each sentence using a pre-trained multilingual model. We use `sentence-transformers` for an easy-to-use interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Data\n",
    "We reload the dataset to ensure we have the text to embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded! Found 16000 sentences.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. Load the data csv we created in the previous step\n",
    "input_file = \"../data/indic_corp_v2_2000.csv\"\n",
    "if not os.path.exists(input_file):\n",
    "    print(\"Error: File not found! Please run Step 1 notebook first.\")\n",
    "else:\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Data loaded! Found {len(df)} sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Initialize Model\n",
    "We use **LaBSE** (Language-agnostic BERT Sentence Embedding) as it is excellent for Indian languages.\n",
    "This model understands many languages and maps similar meanings to similar numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LaBSE model...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajga\\anaconda3\\envs\\NLP\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajga\\anaconda3\\envs\\NLP\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajga\\anaconda3\\envs\\NLP\\Lib\\site-packages\\sentence_transformers\\models\\Dense.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(input_path, \"pytorch_model.bin\"), map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# 2. Load the LaBSE model\n",
    "# This might take a minute to download the first time\n",
    "model_name = \"sentence-transformers/LaBSE\"\n",
    "print(\"Loading LaBSE model...\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Generate Embeddings\n",
    "We encode the sentences. The `encode` function handles batching automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sentences to embeddings... (This may take some time)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8724c29be74a47199a7e43ccb34b3968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding time: 1.54 minutes\n",
      "Done! Created embeddings with shape: (16000, 768)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 3. Convert text to embeddings\n",
    "sentences = df['text'].tolist()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Converting sentences to embeddings... (This may take some time)\")\n",
    "# We use batch_size=64 to process 64 sentences at a time, which is faster\n",
    "embeddings = model.encode(sentences, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Embedding time: {(end - start)/60:.2f} minutes\")\n",
    "print(f\"Done! Created embeddings with shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Add Language Family info for Analysis later\n",
    " We know these facts about Indian languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>text</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>लोगों को बिलों संबंधी सुविधा देना ही उनका काम</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>इनेलो 1987 में उस वक्त ऐसे ही दोराहे पर खड़ी थ...</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>जहां आई थी तबाही उस घाटी क्षेत्र में खतरा ज्यादा</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>इसके बाद केंद्र की ओर से प्रदेश सरकार को पीएमज...</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>यह पूछने पर कि इस बड़े मैच से पहले उनकी नींद ग...</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  iso_code                                               text  \\\n",
       "0    Hindi  hin_Deva      लोगों को बिलों संबंधी सुविधा देना ही उनका काम   \n",
       "1    Hindi  hin_Deva  इनेलो 1987 में उस वक्त ऐसे ही दोराहे पर खड़ी थ...   \n",
       "2    Hindi  hin_Deva   जहां आई थी तबाही उस घाटी क्षेत्र में खतरा ज्यादा   \n",
       "3    Hindi  hin_Deva  इसके बाद केंद्र की ओर से प्रदेश सरकार को पीएमज...   \n",
       "4    Hindi  hin_Deva  यह पूछने पर कि इस बड़े मैच से पहले उनकी नींद ग...   \n",
       "\n",
       "       Family  \n",
       "0  Indo-Aryan  \n",
       "1  Indo-Aryan  \n",
       "2  Indo-Aryan  \n",
       "3  Indo-Aryan  \n",
       "4  Indo-Aryan  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_map = {\n",
    "    'Hindi': 'Indo-Aryan', \n",
    "    'Bengali': 'Indo-Aryan', \n",
    "    'Marathi': 'Indo-Aryan',\n",
    "    'Gujarati': 'Indo-Aryan',\n",
    "    'Tamil': 'Dravidian', \n",
    "    'Telugu': 'Dravidian', \n",
    "    'Kannada': 'Dravidian', \n",
    "    'Malayalam': 'Dravidian'\n",
    "}\n",
    "\n",
    "df['Family'] = df['language'].map(family_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Save Embeddings\n",
    "We save the embeddings and the corresponding metadata (languages) so we don't have to re-compute them in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved:\n",
      "- ../data/embeddings.npy\n",
      "- ../data/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the embeddings and the updated CSV\n",
    "np.save(\"../data/embeddings.npy\", embeddings)\n",
    "df.to_csv(\"../data/metadata.csv\", index=False)\n",
    "\n",
    "print(\"Files saved:\")\n",
    "print(\"- ../data/embeddings.npy\")\n",
    "print(\"- ../data/metadata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
